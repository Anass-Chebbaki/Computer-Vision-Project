{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOIKY2ATr032Bvpt3gmhG59"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **SCRIPT PREPARAZIONE CARTELLE PER IL TRAINING**\n","\n","Questo script ha lo scopo di creare in maniera totalmente automatica tutto il necessario per il training di **YOLO Pose**. In particolare organizza le cartelle in questa disposizionei:\n","\n","*   TRAIN (70%): 210\n","*   VALIDATION (20%): 60\n","*   TEST (10%): 30"],"metadata":{"id":"JPVCqz7mvALV"}},{"cell_type":"markdown","source":["\n","\n","```\n",".\n","└── Training_Dataset/\n","    ├── train/\n","    │   ├── images\n","    │   └── labels\n","    ├── validation/\n","    │   ├── images\n","    │   └── labels\n","    └── test/\n","        ├── images\n","        └── labels\n","```\n","\n"],"metadata":{"id":"4QbFFbBnq36y"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"W5S6UfOkzCRH"}},{"cell_type":"code","source":["# === MOUNT DRIVE ===\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBR-ihW0zRUQ","executionInfo":{"status":"ok","timestamp":1749136664141,"user_tz":-120,"elapsed":18741,"user":{"displayName":"Computer Vision Project","userId":"01767340751956171567"}},"outputId":"af50f2cd-6dfa-4695-9dfc-af559ca6d8b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# === Percorsi ===\n","base_input = \"/content/drive/MyDrive/Computer_Vision_&_Deep_Learning/DATASET/Datasets_PCTO/Dataset_Annotated_PCTO\"\n","images_input = os.path.join(base_input, \"images\")\n","labels_input = os.path.join(base_input, \"labels_corrette\")\n","\n","base_output = \"/content/drive/MyDrive/Computer_Vision_&_Deep_Learning/DATASET/Datasets_PCTO/Dataset_Annotated_PCTO_702010\"\n","splits = {\n","    \"train\": (0, 210),        # 70%\n","    \"validation\": (210, 270), # 20%\n","    \"test\": (270, 300)        # 10%\n","}\n","\n","# === Crea le directory ===\n","for split in splits:\n","    os.makedirs(os.path.join(base_output, split, \"images\"), exist_ok=True)\n","    os.makedirs(os.path.join(base_output, split, \"labels\"), exist_ok=True)\n","\n","# === Elenco immagini ordinato ===\n","all_images = sorted([\n","    f for f in os.listdir(images_input)\n","    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n","])\n","\n","# === Funzione per copiare immagini e labels ===\n","def copy_split(start, end, split_name):\n","    for img_file in all_images[start:end]:\n","        base_name = os.path.splitext(img_file)[0]\n","        label_file = base_name + \".txt\"\n","\n","        src_img_path = os.path.join(images_input, img_file)\n","        src_lbl_path = os.path.join(labels_input, label_file)\n","\n","        dst_img_path = os.path.join(base_output, split_name, \"images\", img_file)\n","        dst_lbl_path = os.path.join(base_output, split_name, \"labels\", label_file)\n","\n","        if os.path.exists(src_lbl_path):\n","            shutil.copy(src_img_path, dst_img_path)\n","            shutil.copy(src_lbl_path, dst_lbl_path)\n","\n","# === Esegui la suddivisione ===\n","for split_name, (start, end) in splits.items():\n","    copy_split(start, end, split_name)\n","\n","print(\"✅ Dataset suddiviso in 70% train, 20% validation, 10% test con immagini e label salvate correttamente.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfRtRbEkup4r","executionInfo":{"status":"ok","timestamp":1749140072625,"user_tz":-120,"elapsed":39752,"user":{"displayName":"Computer Vision Project","userId":"01767340751956171567"}},"outputId":"e64816df-7b9d-49d3-b1a9-ff2fe84d3ed4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Dataset suddiviso in 70% train, 20% validation, 10% test con immagini e label salvate correttamente.\n"]}]},{"cell_type":"markdown","source":["ALTRA VERSIONE PER FARE LA DIVISIONE DEI SET (CON SHUFFLE E PERCENTUALI)"],"metadata":{"id":"jTDyMc6ZjaqM"}},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","\n","# === Percorsi ===\n","base_input = \"/content/drive/MyDrive/Computer_Vision_&_Deep_Learning/DATASET/Datasets_PCTO/Dataset_Annotated_PCTO\"\n","images_input = os.path.join(base_input, \"images\")\n","labels_input = os.path.join(base_input, \"labels_corrette\")\n","\n","base_output = \"/content/drive/MyDrive/Computer_Vision_&_Deep_Learning/DATASET/Datasets_PCTO/Dataset_Annotated_PCTO_702010\"\n","\n","# === Elenco immagini ordinato e con label esistente ===\n","all_images = sorted([\n","    f for f in os.listdir(images_input)\n","    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")) and\n","    os.path.exists(os.path.join(labels_input, os.path.splitext(f)[0] + \".txt\"))\n","])\n","\n","# === Shuffle ===\n","random.seed(42)\n","random.shuffle(all_images)\n","\n","# === Split dinamico ===\n","total = len(all_images)\n","train_split = int(0.7 * total)\n","val_split = int(0.9 * total)\n","\n","splits = {\n","    \"train\": all_images[:train_split],\n","    \"validation\": all_images[train_split:val_split],\n","    \"test\": all_images[val_split:]\n","}\n","\n","# === Crea le directory ===\n","for split in splits:\n","    os.makedirs(os.path.join(base_output, split, \"images\"), exist_ok=True)\n","    os.makedirs(os.path.join(base_output, split, \"labels\"), exist_ok=True)\n","\n","# === Copia file ===\n","for split_name, files in splits.items():\n","    for img_file in files:\n","        base_name = os.path.splitext(img_file)[0]\n","        label_file = base_name + \".txt\"\n","\n","        src_img_path = os.path.join(images_input, img_file)\n","        src_lbl_path = os.path.join(labels_input, label_file)\n","\n","        dst_img_path = os.path.join(base_output, split_name, \"images\", img_file)\n","        dst_lbl_path = os.path.join(base_output, split_name, \"labels\", label_file)\n","\n","        shutil.copy(src_img_path, dst_img_path)\n","        shutil.copy(src_lbl_path, dst_lbl_path)\n","\n","    print(f\"✅ {split_name.capitalize()}: {len(files)} immagini copiate\")\n","\n","print(\"\\n✔️ Dataset suddiviso in train (70%), validation (20%), test (10%) con shuffle e controllo label.\")\n"],"metadata":{"id":"gUliRZQbjgaF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"_-_JZBUy0utU"}},{"cell_type":"markdown","source":["# **SCRIPT DATA AUGMENTATION E DIRECTORY TRAINING**\n","\n","Prende le 210 immagini di training dalla directory Dataset_Annotated_PCTO_702010/train/.\n","\n","Per ognuna:\n","\n","* la copia nella nuova directory Training_Test_BadAnnotation_YesAugmentation/images/train/\n","\n","* crea 2 versioni augmentate applicando:\n","\n","  * rotazione ±10°\n","\n","  * flip orizzontale\n","\n","  * variazioni di luminosità/contrasto\n","\n","  * sfocatura gaussiana\n","\n","aggiorna e salva i corrispondenti file .txt delle annotazioni keypoints.\n","\n","Copia anche la parte validation già esistente nel posto giusto.\n","\n","Mantiene 15 keypoints per ogni bbox (con padding se necessario)."],"metadata":{"id":"Dl8fGCgw0OyY"}},{"cell_type":"code","source":["!pip install -q albumentations"],"metadata":{"id":"5MP7Vjeg1WqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import shutil\n","import albumentations as A\n","\n","# === Percorsi ===\n","base_input = \"/content/drive/MyDrive/Computer_Vision_&_Deep_Learning/DATASET/Datasets_PCTO/Dataset_Annotated_PCTO_702010\"\n","train_img_input = os.path.join(base_input, \"train\", \"images\")\n","train_lbl_input = os.path.join(base_input, \"train\", \"labels\")\n","\n","base_output = \"/content/drive/MyDrive/Computer_Vision_&_Deep_Learning/DATASET/Training_Test_Datasets/Training_Test_BadAnnotation_YesAugmentation\"\n","train_img_out = os.path.join(base_output, \"images\", \"train\")\n","train_lbl_out = os.path.join(base_output, \"labels\", \"train\")\n","\n","# === Crea cartelle output se non esistono ===\n","os.makedirs(train_img_out, exist_ok=True)\n","os.makedirs(train_lbl_out, exist_ok=True)\n","\n","# === Copia val così com'è (solo se non già fatto) ===\n","val_img_src = os.path.join(base_input, \"validation\", \"images\")\n","val_lbl_src = os.path.join(base_input, \"validation\", \"labels\")\n","val_img_dst = os.path.join(base_output, \"images\", \"val\")\n","val_lbl_dst = os.path.join(base_output, \"labels\", \"val\")\n","os.makedirs(val_img_dst, exist_ok=True)\n","os.makedirs(val_lbl_dst, exist_ok=True)\n","for src_folder, dst_folder in [(val_img_src, val_img_dst), (val_lbl_src, val_lbl_dst)]:\n","    for file in os.listdir(src_folder):\n","        shutil.copy(os.path.join(src_folder, file), os.path.join(dst_folder, file))\n","\n","# === Definizione della trasformazione ===\n","transform = A.Compose([\n","    A.Rotate(limit=10, p=0.5),\n","    A.HorizontalFlip(p=0.3),\n","    A.RandomBrightnessContrast(p=0.4),\n","    A.GaussianBlur(p=0.2)\n","], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n","\n","# === Funzione di conversione e augmentazione ===\n","def augment_and_save(image_path, label_path, output_img_dir, output_lbl_dir):\n","    image = cv2.imread(image_path)\n","    h, w = image.shape[:2]\n","    base_name = os.path.splitext(os.path.basename(image_path))[0]\n","\n","    with open(label_path, 'r') as f:\n","        lines = f.readlines()\n","\n","    # Parse ogni oggetto\n","    objects = []\n","    for line in lines:\n","        parts = line.strip().split()\n","        class_id = int(parts[0])\n","        xc, yc, bw, bh = map(float, parts[1:5])\n","        keypoints = []\n","        for i in range(5, len(parts), 3):\n","            xk, yk, v = float(parts[i]), float(parts[i+1]), int(parts[i+2])\n","            keypoints.append((xk, yk, v))\n","        objects.append((class_id, [xc, yc, bw, bh], keypoints))\n","\n","    for aug_idx in range(1, 3):  # 2 immagini aumentate\n","        bboxes = [obj[1] for obj in objects]\n","        keypoints_all = [kp for obj in objects for kp in obj[2]]\n","        visibility = [kp[2] for kp in keypoints_all]\n","        visible_kp = [(kp[0], kp[1]) for kp in keypoints_all if kp[2] > 0]\n","\n","        try:\n","            augmented = transform(image=image, bboxes=bboxes, keypoints=visible_kp)\n","        except Exception as e:\n","            print(f\"❌ Errore su {image_path}: {e}\")\n","            continue\n","\n","        aug_image = augmented['image']\n","        aug_bboxes = augmented['bboxes']\n","        aug_keypoints = augmented['keypoints']\n","\n","        new_lines = []\n","        idx_kp = 0\n","        for j, (class_id, _, _) in enumerate(objects):\n","            x_c, y_c, bw, bh = aug_bboxes[j]\n","            line = [str(class_id), str(x_c), str(y_c), str(bw), str(bh)]\n","            for _ in range(15):  # 15 keypoint attesi\n","                if idx_kp < len(aug_keypoints):\n","                    xk, yk = aug_keypoints[idx_kp]\n","                    vk = visibility[idx_kp]\n","                    xk = min(max(xk, 0.0), 1.0)\n","                    yk = min(max(yk, 0.0), 1.0)\n","                    line.extend([str(xk), str(yk), str(vk)])\n","                    idx_kp += 1\n","                else:\n","                    line.extend(['0.0', '0.0', '0'])\n","            new_lines.append(' '.join(line))\n","\n","        # Salvataggio immagini e labels\n","        new_img_name = f\"{base_name}_aug{aug_idx}.jpg\"\n","        new_lbl_name = f\"{base_name}_aug{aug_idx}.txt\"\n","\n","        cv2.imwrite(os.path.join(output_img_dir, new_img_name), aug_image)\n","        with open(os.path.join(output_lbl_dir, new_lbl_name), 'w') as f:\n","            f.write('\\n'.join(new_lines))\n","\n","# === Esegui su tutto il train ===\n","for img_file in sorted(os.listdir(train_img_input)):\n","    if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n","        continue\n","    base_name = os.path.splitext(img_file)[0]\n","    img_path = os.path.join(train_img_input, img_file)\n","    lbl_path = os.path.join(train_lbl_input, base_name + \".txt\")\n","\n","    # Copia originali\n","    shutil.copy(img_path, os.path.join(train_img_out, img_file))\n","    shutil.copy(lbl_path, os.path.join(train_lbl_out, base_name + \".txt\"))\n","\n","    # Augmenta e salva\n","    augment_and_save(img_path, lbl_path, train_img_out, train_lbl_out)\n","\n","\"✅ Augmentazione completata. Tutti i dati salvati in Training_Test_BadAnnotation_YesAugmentation/\"\n"],"metadata":{"id":"RCm-2JJ50v__"},"execution_count":null,"outputs":[]}]}